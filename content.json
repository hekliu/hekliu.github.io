{"pages":[{"title":"关于","text":"一个喜欢玩游戏，热爱编程的九零后少年…; 业余骑行，运动，看电影，偶尔打打游戏，单身狗的日常生活 (～￣▽￣)～写博客，撸代码，研究技术，提升自我","link":"/about/index.html"},{"title":"目录","text":"","link":"/categories/index.html"},{"title":"标签云","text":"","link":"/tags/index.html"}],"posts":[{"title":"对于一些HashMap的一些疑问","text":"HashMap的结构数组的寻址快，但是数据的插入与删除速度不行。链表的插入与删除速度快，但是寻址速度不行。 那有没有一种两者兼具的数据结构，答案肯定是有的，那就是hash表。 HashMap 就是根据 数组+链表 的方式组成了 hash 表： 对于HashMap的一些疑问 一、HashMap的resize过程是什么样的？HashMap在put的时候会先检查当前数组的length,如果插入新的值的时候使得 length &gt; 0.75f * size（f为加载因子，可以在创建hashMap时指定）的话，会将数组进行扩容为当前容量的2倍。 扩容之后必定要将原有 hashMap 中的值拷贝到新容量的hashMap 里面，HashMap 默认的容量为16，加载因子为0.75， 也就是说当HashMap 中Entry的个数超过 16 * 0.75 = 12时, 会将容量扩充为 16 * 2 = 32，然后重新计算元素在数组中的位置，这是一个非常耗时的操作，所以我们在使用HashMap的时候如果能预先知道Map中元素的大小，预设其大小能够提升其性能。 resize代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475//HashMap数组扩容void resize(int newCapacity) {Entry[] oldTable = table;int oldCapacity = oldTable.length;//如果当前的数组长度已经达到最大值，则不在进行调整if (oldCapacity == MAXIMUM_CAPACITY) {threshold = Integer.MAX_VALUE;return;}//根据传入参数的长度定义新的数组Entry[] newTable = new Entry[newCapacity];//按照新的规则，将旧数组中的元素转移到新数组中transfer(newTable);table = newTable;//更新临界值threshold = (int)(newCapacity * loadFactor);}//旧数组中元素往新数组中迁移void transfer(Entry[] newTable) {//旧数组Entry[] src = table;//新数组长度int newCapacity = newTable.length;//遍历旧数组for (int j = 0; j &lt; src.length; j++) {Entry e = src[j];if (e != null) {src[j] = null;do {Entry next = e.next;int i = indexFor(e.hash, newCapacity);//放在新数组中的index位置e.next = newTable[i];//实现链表结构，新加入的放在链头，之前的的数据放在链尾newTable[i] = e;e = next;} while (e != null);}}} 这是1.7中的代码，1.8中引入了红黑树的概念，代码会相对复杂一些。 二、HashMap在扩容的时候为什么容量都是原来的2倍，即容量为2^nHashMap 在计算数组中key的位置时，使用的算法为：12345/* Returns index for hash code h. */static int indexFor(int h, int length) { // assert Integer.bitCount(length) == 1 : \"length must be a non-zero power of 2\"; return h &amp; (length-1); } 即对key的hashcode 与当前数组容量 -1 进行与操作 我们假设有一个容量为分别为 15 和 16 的hashMap ，有两个key的hashcode 分别为 4 和 5 ，进行indexFor操作之后： 1H &amp; (length -1) hash &amp; table.length-1 4 &amp; (15 - 1) 0100 &amp; 1110 = 0100 5 &amp; （ 15 -1 ） 0101 &amp; 1110 = 01004 &amp; (16 - 1) 0100 &amp; 1111 = 0100 5 &amp; （ 16 -1 ） 0101 &amp; 1111 = 0101 我们能够看到在容量为16时进行indexFor操作之后获得相同结果的几率要比容量为15时的几率要小，这样能够减少出现hash冲突的几率，从而提高查询效率。2 ^ n是一个非常神奇的数字。 三、put时出现相同的hashcode会怎样？hashMap 里面存储的Entry对象是由数组和链表组成的，当key的hashcode相同时，数组上这个位置存储的结构就是链表，这时会将新的值插入链表的表头。进行取值的时候会先获取到链表，再对链表进行遍历，通过key.equals方法获取到值。（hashcode相同不代表对象相同，不要混淆hashcode和equals方法）所以声明作final的对象，并且采用合适的equals()和hashCode()方法的话，将会减少碰撞的发生，提高效率。不可变性使得能够缓存不同键的hashcode，这将提高整个获取对象的速度，使用String，Interger这样的wrapper类作为键是非常好的选择。 四、什么是循环链表？HashMap在遇到多线程的操作中，如果需要重新调整HashMap的大小时，多个线程会同时尝试去调整HashMap的大小，这时处在同一位置的链表的元素的位置会反过来，以为移动到新的bucket的时候，HashMap不会将新的元素放到尾部（为了避免尾部遍历），这时可能会出现A -&gt; B -&gt; A的情况，从而出现死循环，这便是HashMap中的循环链表。 所以HashMap 是不适合用在多线程的情况下的，可以考虑尝试使用HashTable 或是 ConcurrentHashMap 五、如何正确使用HashMap提高性能在设置HashMap的时候指定其容量的大小，减少其resize的过程。 六、JDK1.8对HashMap进行了哪些优化jdk1.8在对hash冲突的key时，如果此bucket位置上的元素数量在10以下时，还是和原来一样使用链表来进行存储，这时寻址的时间复杂度为O(n),当元素数量超过10时，使用红黑树进行代替，这时寻址的时间复杂度为O(n) 七、HashMap 与 HashTable、ConcurrentHashMap的区别1.HashTable的方法是同步的，在方法的前面都有synchronized来同步，HashMap未经同步，所以在多线程场合要手动同步 2.HashTable不允许null值(key和value都不可以) ,HashMap允许null值(key和value都可以)。 3.HashTable有一个contains(Object value)功能和containsValue(Object value)功能一样。 4.HashTable使用Enumeration进行遍历，HashMap使用Iterator进行遍历。 5.HashTable中hash数组默认大小是11，增加的方式是 old * 2 + 1。HashMap中hash数组的默认大小是16，而且一定是2的指数。 6.哈希值的使用不同，HashTable直接使用对象的hashCode，而HashMap重新计算hash值，用与代替求 7.ConcurrentHashMap也是一种线程安全的集合类，他和HashTable也是有区别的，主要区别就是加锁的粒度以及如何加锁，ConcurrentHashMap的加锁粒度要比HashTable更细一点。将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 八、ConcurrentHashMap 和 Hashtable 的区别ConcurrentHashMap 和 Hashtable 的区别主要体现在实现线程安全的方式上不同。 底层数据结构：JDK1.7的 ConcurrentHashMap 底层采用 分段的数组+链表 实现，JDK1.8 采用的数据结构跟HashMap1.8的结构一样，数组+链表/红黑二叉树。Hashtable 和 JDK1.8 之前的 HashMap 的底层数据结构类似都是采用 数组+链表 的形式，数组是 HashMap 的主体，链表则是主要为了解决哈希冲突而存在的； 实现线程安全的方式（重要）：在JDK1.7的时候，ConcurrentHashMap（分段锁）对整个桶数组进行了分割分段(Segment)，每一把锁只锁容器其中一部分数据，多线程访问容器里不同数据段的数据，就不会存在锁竞争，提高并发访问率。（默认分配16个Segment，比Hashtable效率提高16倍。）到了 JDK1.8 的时候已经摒弃了Segment的概念，而是直接用 Node数组+链表+红黑树的数据结构来实现，并发控制使用 synchronized 和 CAS 来操作。（JDK1.6以后 对 synchronized锁做了很多优化）整个看起来就像是优化过且线程安全的 HashMap，虽然在JDK1.8中还能看到 Segment 的数据结构，但是已经简化了属性，只是为了兼容旧版本； Hashtable(同一把锁) :使用 synchronized 来保证线程安全，效率非常低下。当一个线程访问同步方法时，其他线程也访问同步方法，可能会进入阻塞或轮询状态，如使用 put 添加元素，另一个线程不能使用 put 添加元素，也不能使用 get，竞争会越来越激烈效率越低。 九、HashMap 多线程操作导致死循环问题在多线程下，进行 put 操作会导致 HashMap 死循环，原因在于 HashMap 的扩容 resize()方法。由于扩容是新建一个数组，复制原数据到数组。由于数组下标挂有链表，所以需要复制链表，但是多线程操作有可能导致环形链表。复制链表过程如下:以下模拟2个线程同时扩容。假设，当前 HashMap 的空间为2（临界值为1），hashcode 分别为 0 和 1，在散列地址 0 处有元素 A 和 B，这时候要添加元素 C，C 经过 hash 运算，得到散列地址为 1，这时候由于超过了临界值，空间不够，需要调用 resize 方法进行扩容，那么在多线程条件下，会出现条件竞争，模拟过程如下： 线程一：读取到当前的 HashMap 情况，在准备扩容时，线程二介入 线程二：读取 HashMap，进行扩容 线程一：继续执行 这个过程为，先将 A 复制到新的 hash 表中，然后接着复制 B 到链头（A 的前边：B.next=A），本来 B.next=null，到此也就结束了（跟线程二一样的过程），但是，由于线程二扩容的原因，将 B.next=A，所以，这里继续复制A，让 A.next=B，由此，环形链表出现：B.next=A; A.next=B 推荐阅读： jdk1.8中ConcurrentHashMap的实现原理 HashMap? ConcurrentHashMap? 相信看完这篇没人能难住你！ HASHMAP、HASHTABLE、CONCURRENTHASHMAP的原理与区别 ConcurrentHashMap实现原理及源码分析 java-并发-ConcurrentHashMap高并发机制-jdk1.8","link":"/2018/10/16/对于HashMap的一些疑问/"},{"title":"tomcat出现的PermGen Space问题","text":"问题：最近做项目碰到了让我纠结的问题，tomcat服务器运行一段时间，总是会自动报异常：java.lang.OutOfmemoryError: PermGen Space 的错误，导致项目无法正常运行。 介绍：PermGen Space：指的是内存的永久保存区，该块内存主要是被JVM用来存放class和mete信息的，当class被加载loader 的时候就会被存储到该内存区中，与存放类的实例的 heap 区不同，java中的 垃圾回收器GC 不会在主程序运行期对PermGen space进行清理。 原因：当我们的应用中有很多的class时，很可能就会出现PermGen space的错误。我们的tomcat在重启的时候，不是使用的 ./bin/shutdown.sh 而是使用kill -9 xxx直接杀掉，这样的话，存在PermGen space里面的内存不会被释放的，这样多长进行 kill 之后，就会导致系统的内存被渐渐吃完了，直到最后tomcat报错。 解决方法：手动设置 MaxPermSize 的大小 1.修改 TOMCAT_HOME/bin/catalina.bat文件在echo &quot;using CATALINA_BASE：$CATALINA_BASE&quot;上面加入这一行内容：1set JAVA_OPTS=%JAVA_OPTS% -server -XX:PermSize=128m -XX:MaxPermSize=512m 2.如果是 linux 环境，则修改 TOMCAT_HOME/bin/catalina.sh:1JAVA_OPTS=\"$JAVA_OPTS\" -server -XX:PermSize=128m -XX:MaxSize=512m 3.修改 TOMCAT_HOME/bin/catalina.bat 文件的内容：在 %_EXECJAVA% %JAVA_OPTS% 后面添加 -Xms=256m -Xmx512m 注意：前后有空格的例如： %_EXECJAVA% %JAVA_OPTS% -Xms=256m -Xmx512m(空格)后面的内容不变 1.在关闭重启 tomcat 的过程中使用 shutdown.sh 而不是 使用 kill -9 2.如果使用 shutdown.sh 不能将tomcat关掉的话，就必须要使用 kill -9 来关闭了，这个时候只有手动的来回收垃圾了： 在 linux 命令下执行如下的命令，把缓存给丢弃掉。 1echo 3 &gt; /proc/sys/vm/drop_caches 关于 drop_caches内容可以参考：drop_caches","link":"/2019/09/30/tomcat出现的PermGen-Space问题/"},{"title":"配置docker官方源并用yum安装docker","text":"一、docker的官方安装文档：https://docs.docker.com/engine/installation/linux/centos/由docker给的文档可以看出它也只是去配置了一个docker的yum源、然后就通过这个源来安装docker了；在这个文档下我们采用手工配置的方式。 二、配置一个docker用的源：1.为docker 增加一个新的yum配置文件； 1touch /etc/yum.repos.d/docker.repo 2.docker.repo的内容如下 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162[docker-ce-stable]name=Docker CE Stable - $basearchbaseurl=https://download.docker.com/linux/centos/7/$basearch/stableenabled=1gpgcheck=0 #我把这里设置成了0、说明我信任了这个源，不对它的rpm进行检察gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-stable-debuginfo]name=Docker CE Stable - Debuginfo $basearchbaseurl=https://download.docker.com/linux/centos/7/debug-$basearch/stableenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-stable-source]name=Docker CE Stable - Sourcesbaseurl=https://download.docker.com/linux/centos/7/source/stableenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-edge]name=Docker CE Edge - $basearchbaseurl=https://download.docker.com/linux/centos/7/$basearch/edgeenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-edge-debuginfo]name=Docker CE Edge - Debuginfo $basearchbaseurl=https://download.docker.com/linux/centos/7/debug-$basearch/edgeenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-edge-source]name=Docker CE Edge - Sourcesbaseurl=https://download.docker.com/linux/centos/7/source/edgeenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-test]name=Docker CE Test - $basearchbaseurl=https://download.docker.com/linux/centos/7/$basearch/testenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-test-debuginfo]name=Docker CE Test - Debuginfo $basearchbaseurl=https://download.docker.com/linux/centos/7/debug-$basearch/testenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg[docker-ce-test-source]name=Docker CE Test - Sourcesbaseurl=https://download.docker.com/linux/centos/7/source/testenabled=0gpgcheck=1gpgkey=https://download.docker.com/linux/centos/gpg 三、安装docker:12345678910111213141516171819202122232425262728sudo yum install docker-ceLoaded plugins: fastestmirror, langpacksLoading mirror speeds from cached hostfileResolving Dependencies--&gt; Running transaction check---&gt; Package docker-ce.x86_64 0:17.03.1.ce-1.el7.centos will be installed--&gt; Processing Dependency: docker-ce-selinux &gt;= 17.03.1.ce-1.el7.centos for package: docker-ce-17.03.1.ce-1.el7.centos.x86_64--&gt; Running transaction check---&gt; Package docker-ce-selinux.noarch 0:17.03.1.ce-1.el7.centos will be installed--&gt; Finished Dependency ResolutionDependencies Resolved===================================================================================================================================== Package Arch Version Repository Size=====================================================================================================================================Installing: docker-ce x86_64 17.03.1.ce-1.el7.centos docker-ce-stable 19 MInstalling for dependencies: docker-ce-selinux noarch 17.03.1.ce-1.el7.centos docker-ce-stable 28 kTransaction Summary=====================================================================================================================================Install 1 Package (+1 Dependent package)Total download size: 19 MInstalled size: 19 MIs this ok [y/d/N]: y 四、直接下载rpm包的方式来安装： 1.我在安装docker的时候发现下载的速度只有 3kB/s ，然而文件大小有19M。就在我感觉安装无望的时候，我机智的想到了自己直接把rpm下载下来，看了下docker.repo 发现centos7的源地址是 https://download.docker.com/linux/centos/7/$basearch/stable 所以我只要去https://download.docker.com/linux/centos/7/x86_64/stable/Packages/ 用迅雷(我是会员有加速)把rpm包下载下来就行了。 下载如下文件： docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpmdocker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm 五、安装docker:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748lltotal 19096-rwxrwxrwx 1 jianglexing jianglexing 19521288 May 30 20:05 docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm-rw-r--r-- 1 jianglexing jianglexing 29108 May 30 20:15 docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm[root@workstudio docker]# yum localinstall *Loaded plugins: fastestmirror, langpacksExamining docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm: docker-ce-17.03.0.ce-1.el7.centos.x86_64Marking docker-ce-17.03.0.ce-1.el7.centos.x86_64.rpm to be installedExamining docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm: docker-ce-selinux-17.03.0.ce-1.el7.centos.noarchMarking docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch.rpm to be installedResolving Dependencies--&gt; Running transaction check---&gt; Package docker-ce.x86_64 0:17.03.0.ce-1.el7.centos will be installed---&gt; Package docker-ce-selinux.noarch 0:17.03.0.ce-1.el7.centos will be installed--&gt; Finished Dependency ResolutionDependencies Resolved===================================================================================================================================== Package Arch Version Repository Size=====================================================================================================================================Installing: docker-ce x86_64 17.03.0.ce-1.el7.centos /docker-ce-17.03.0.ce-1.el7.centos.x86_64 65 M docker-ce-selinux noarch 17.03.0.ce-1.el7.centos /docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch 43 kTransaction Summary=====================================================================================================================================Install 2 PackagesTotal size: 65 MInstalled size: 65 MIs this ok [y/d/N]: yDownloading packages:Running transaction checkRunning transaction testTransaction test succeededRunning transaction Installing : docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch 1/2 setsebool: SELinux is disabled.libsemanage.semanage_direct_install_info: Overriding docker module at lower priority 100 with module at priority 400. Installing : docker-ce-17.03.0.ce-1.el7.centos.x86_64 2/2 Verifying : docker-ce-17.03.0.ce-1.el7.centos.x86_64 1/2 Verifying : docker-ce-selinux-17.03.0.ce-1.el7.centos.noarch 2/2 Installed: docker-ce.x86_64 0:17.03.0.ce-1.el7.centos docker-ce-selinux.noarch 0:17.03.0.ce-1.el7.centos Complete! 六、启动docker:12345[root@workstudio docker]# systemctl start docker[root@workstudio docker]# ps -ef | grep dockerroot 4458 1 1 20:22 ? 00:00:00 /usr/bin/dockerdroot 4465 4458 0 20:22 ? 00:00:00 docker-containerd -l unix:///var/run/docker/libcontainerd/docker-containerd.sock --metrics-interval=0 --start-timeout 2m --state-dir /var/run/docker/libcontainerd/containerd --shim docker-containerd-shim --runtime docker-runcroot 4589 4333 0 20:22 pts/1 00:00:00 grep --color=auto docker 七、测试docker是否能成功运行：1234567891011121314151617181920212223242526[root@workstudio docker]# docker run hello-worldUnable to find image 'hello-world:latest' locallylatest: Pulling from library/hello-world78445dd45222: Pull complete Digest: sha256:c5515758d4c5e1e838e9cd307f6c6a0d620b5e07e6f927b07d05f6d12a1ac8d7Status: Downloaded newer image for hello-world:latestHello from Docker!This message shows that your installation appears to be working correctly.To generate this message, Docker took the following steps: 1. The Docker client contacted the Docker daemon. 2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub. 3. The Docker daemon created a new container from that image which runs the executable that produces the output you are currently reading. 4. The Docker daemon streamed that output to the Docker client, which sent it to your terminal.To try something more ambitious, you can run an Ubuntu container with: $ docker run -it ubuntu bashShare images, automate workflows, and more with a free Docker ID: https://cloud.docker.com/For more examples and ideas, visit: https://docs.docker.com/engine/userguide/ 如果是第一次运行 hello-world ，这个 docker-image 由于它还不存在于本地，所以要下载它，这可能要用一点时间！","link":"/2019/09/30/配置docker官方源并用yum安装docker/"},{"title":"Dockerfile极简入门与实践","text":"前文中，罗列了docker使用中用到的基本命令此文，将会对怎样使用Dockerfile去创建一个镜像做简单的介绍 Dockerfile命令要开始编写Dockerfile，首先要对相关的命令有个清晰的认识下面列出了部分Dockerfile命令的功能以及使用方法，供参考： 1. FROMDockerfile的第一条指定必须是FROM，用于指定基础镜像。用法：FROM [image]:[tag] 2. MAINTAINER用于指定此Dockerfile维护者信息。用法：MAINTAINER &lt;name&gt; &lt;email&gt; 3. ADD复制指定内容到镜像中，指定内容可以是一个相对或绝对路径，也可以是一个url(此时相当于wget)，如果添加的文件是个tar压缩文件，文件在复制的时候会自动解压。用法：ADD &lt;src&gt; &lt;dest&gt; 4. COPY与ADD命令用法相同，区别是COPY只能复制本地文件用法：COPY &lt;src&gt; &lt;dest&gt; 5. RUN构建镜像时运行指定命令，建议多个命令尽量写在同一个RUN中，用&amp;&amp;分割或使用\\换行。用法：RUN &lt;command&gt;RUN [&quot;executable&quot;, &quot;param1&quot;, &quot;param2&quot;]前者在shell终端上运行，后者使用exec运行。 6. CMD容器启动时运行指定命令，每个容器只能执行一条CMD命令，多个CMD命令时，只最后一条被执行。用法：CMD [&quot;executable&quot;,&quot;param1&quot;,&quot;param2&quot;]CMD [&quot;param1&quot;,&quot;param2&quot;]CMD &lt;command&gt; &lt;param1&gt; &lt;param2&gt; 7. ENV指定一个环境变量，可以被RUN,WORKDIR命令使用，并在容器运行时保持。用法:ENV &lt;key&gt; &lt;value&gt;ENV &lt;key1&gt;=&lt;value1&gt; &lt;k2&gt;=&lt;v2&gt; &lt;k3&gt;=&lt;v3&gt; ... 8. ENTRYPOINT配置容器启动后执行的命令，并且不可被 docker run 提供的参数覆盖，每个Dockerfile中只能有一个 ENTRYPOINT ，当指定多个时，只有最后一个起效。用法：ENTRYPOINT [“executable”, “param1”, “param2”]ENTRYPOINT &lt;command&gt; &lt;param1&gt; &lt;param2&gt; 9. WORKDIR设置工作目录，对RUN,CMD,ENTRYPOINT,COPY,ADD生效。如果不存在则会创建。用法：WORKDIR &lt;path&gt; 10. EXPOSE功能为暴漏容器运行时的监听端口给外部用法：EXPOSE &lt;port&gt; Dockerfile实践通读过上面的Dockerfile命令，相信对编写一个Dockerfile有了一个初步的认识接着，我们来通过一个具体的需求，来看一个完整的镜像是怎么通过Dockerfile生成的 1. 需求使用32位的jre环境运行一个dubbo服务的jar包 2. 编写Dockerfile首先，我们需要一个32位的jre环境，你可以从镜像仓库找一个，但此处，我们选择通过Dockerfile自己创建 123456789101112# 指定基础镜像FROM i386/centos:6# 作者信息MAINTAINER trainoo \"trainoo@163.com\"# 添加jre环境，add会自动解压ADD jre-8u211-linux-i586.tar.gz /opt/docker/java/jre8# 设置java环境变量ENV JAVA_HOME=/opt/docker/java/jre8/jre1.8.0_211 \\ CLASSPATH=$JAVA_HOME/bin \\ PATH=.:$JAVA_HOME/bin:$PATH# 容器启动后执行，显示java版本号，可以查看环境是否安装成功CMD [\"java\",\"-version\"] 问：为什么使用 i386/centos:6 作为基础镜像？ 答：因为32位的jre当然是使用32位的环境运行比较方便 如果使用64位的环境运行32位jre也是可以的，但是需要安装如下依赖： RUN yum update &amp;&amp; yum -y install glibc.i686 zlib.i686 libstdc++.i686 如果打包的是64位的jre，那么基础镜像可以换成：frolvlad/alpine-glibc 问：jre-8u211-linux-i586.tar.gz 这个包从哪下载？ 答：你可以从官网下载，当然，你看到此文章时，可能网址已经变化。 3. 构建如上，我们写好了一个Dockerfile，只需把jre包跟Dockerfile放在同一路径即可开始构建，命令如下：docker build -t jre8-64:second .ps: 此处应该贴32位的运行过程的，但是64位的跟32位没太大区别，所以就这样吧 12345678910111213141516171819202122232425262728293031[root@xxx jre8-x32]# lltotal 89060-rw-r--r--. 1 root root 369 Jun 27 18:38 Dockerfile-rw-r--r--. 1 root root 91192891 Jun 26 14:52 jre-8u211-linux-i586.tar.gz[root@xxx jre8-x64]# docker build -t jre8-64:second .Sending build context to Docker daemon 87.86MBStep 1/5 : FROM frolvlad/alpine-glibc:alpine-3.10 ---&gt; 74b43ef19206Step 2/5 : MAINTAINER trainoo \"trainoo@163.com\" ---&gt; Using cache ---&gt; 1257f5f17f2aStep 3/5 : ADD jre-8u211-linux-x64.tar.gz /opt/docker/java/jre8 ---&gt; Using cache ---&gt; 10692b79be49Step 4/5 : ENV JAVA_HOME=/opt/docker/java/jre8/jre1.8.0_211 CLASSPATH=$JAVA_HOME/bin PATH=.:$JAVA_HOME/bin:$PATH ---&gt; Running in 1710cc8fd3aaRemoving intermediate container 1710cc8fd3aa ---&gt; 5dd2f0ae922cStep 5/5 : CMD [\"java\",\"-version\"] ---&gt; Running in 368238c0940bRemoving intermediate container 368238c0940b ---&gt; e6e9cf729e37Successfully built e6e9cf729e37Successfully tagged jre8-64:second[root@xxx jre8-x64]# docker images -f reference=jre8*REPOSITORY TAG IMAGE ID CREATED SIZEjre8-64 second e6e9cf729e37 53 seconds ago 251MBjre8-32 base 9035f0dcd0ed 20 hours ago 433MBjre8-64 base ce0823b7fdc3 47 hours ago 251MB 由上面的构建步骤可以看出，每运行一个命令，都会产生一个临时镜像，所以为了避免产生多余的临时镜像，我们要尽量的把多个相同指令的的构建步骤，写在同一行里。 4. 运行项目假设我们把项目打包好了，打包好的jar包为：my-service-1.0.jar。 123456789FROM jre8-32:baseMAINTAINER trainoo \"trainoo@163.com\"COPY ./jar/ /opt/dubbo-server/RUN cd /opt/dubbo-server/ &amp;&amp; mv $(ls | grep jar) app.jarWORKDIR /opt/dubbo-server/CMD [\"java\",\"-Xms512M\",\"-Xmx512M\",\"-jar\",\"app.jar\"]// 为了通用性，这里把jar文件(如果不是springboot项目，还有lib等依赖包)放在jar目录下，COPY时一起复制过去// 同样目的，使用 mv $(ls | grep jar) app.jar 将需要被执行的jar文件统一命名成 app.jar 1234567# 构建镜像[root@xxx jre8-x64]# docker build -t myservice:v1 ......此处省略部分.....# 启动容器[root@xxx jre8-x64]# docker run -d --name myservice myservice:v1# 查看容器[root@xxx jre8-x64]# docker ps 后续总结事情总是不会这么顺利，中途总是会有一些小插曲，所以下面是可能遇到的问题的解决方案 docker 批量删除产生的缓存镜像123456789# 第一种风格docker ps -a | grep \"Exited\" | awk '{print $1 }'|xargs docker stopdocker ps -a | grep \"Exited\" | awk '{print $1 }'|xargs docker rmdocker images | grep none | awk '{print $3}' | xargs docker rmi# 第二种风格docker rm $(docker ps -aq -f exited=137)docker rm $(docker ps -aq -f status=exited)docker rmi $(docker images -qa -f reference=*:v1) container 时区跟 host 不一致12345# Dockerfile中添加RUN echo \"Asia/Shanghai\" &gt; /etc/timezone# 启动时添加：-v /etc/localtime:/etc/localtime:rodocker run -d -v /etc/localtime:/etc/localtime:ro --net mynet --name myservice myservice:v1 docker运行项目，日志中文显示???12345# Dockerfile中添加，指定语言环境RUN localedef -i en_US -f UTF-8 en_US.UTF-8ENV LANG en_US.UTF-8 ENV LANGUAGE en_US:en ENV LC_ALL en_US.UTF-8","link":"/2019/10/05/Dockerfile极简入门与实践/"},{"title":"Docker基本命令入门","text":"目前容器技术使用相当广泛不会或者没有使用过容器感觉都不像是个搞技术的所以，我也就docker相关内容做一个整理只有不断的学习，才能保持自己的竞争力 什么是容器？容器是一种轻量级、可移植、自包含的软件打包技术，使应用程序可以在几乎任何地方以相同的方式运行。 为什么使用容器？容器使软件具备了超强的可移植能力 怎样使用容器？容器常用的基本操作：123456789101112131415docker stop\\start\\restart [container_id\\container_name] // 停止、启动、重启容器docker kill [container_id\\container_name] // 强制停止docker pause\\unpause [container_id\\container_name] // 暂停、取消暂停docker rm [container_id\\container_name] // 删除容器docker rmi [image_id\\image_name] // 删除镜像// 按条件查找容器id, -a 所有 -q 只显示id -f filter过滤docker ps -aq -f status=runningdocker ps -aq -f status=exiteddocker ps -aq -f status=created// 查看容器日志docker logs -f &lt;container&gt;// 进入shelldocker exec -it &lt;container&gt; sh// 进入bashdocker exec -it &lt;container&gt; /bin/bash 限制容器内存使用：-m 或 –memory 设置内存的使用限额、–memory-swap 设置内存+swap的使用限额1docker run -m 200M --memory-swap=300M ubuntu 限制容器CPU使用：-c 或 –cpu-shares 设置权重、 –cpu 设置工作线程数量1docker run -it -c 1024 progrium/stress --cpu 1 限制容器IO的使用：–blkio-weight 设置block IO的优先级1docker run -it --name my_ubuntu --blkio-weight 600 ubuntu 创建自定义IP网段的容器网络： 1docker network create --driver bridge --subnet 172.22.22.0/24 --gateway 172.22.22.1 my_net 启动时给容器指定一个静态ip：只有使用 –subnet 创建的网络才能指定静态ip1docker run -it --network=my_net --ip 172.22.22.22 busybox 查看容器网络：1docker network ls 共享网络栈：使用 –network=container:web1 指定 jointed 容器为 web1 将主机上的目录或者文件挂载到容器：使用 -v : 将其 mount 到容器12docker run -d -p 80:80 -v ~/htdocs:/usr/local/apache2/htdocs httpddocker run -d -p 80:80 -v ~/htdocs:/usr/local/apache2/htdocs:ro httpd // ro设置只读权限，容器不能对该文件做修改 使用volume container共享容器数据：通过 –volumes-from 使用 vc_data 这个volume container123451.创建一个vc：docker create --name vc_data -v ~/htdocs:/usr/local/apache2/htdocs -v /other/useful/tools busybox2.共享vc：docker run --name web1 -d -p 80 --volumes-from vc_data httpddocker run --name web2 -d -p 80 --volumes-from vc_data httpd docker删除bind mount：只能由host负责删除docker删除docker managed volume：删除容器时加上 -v 可以删除容器依赖的volume如果删除容易时，没有加-v删除依赖volume，也可以用：docker volume rm &lt;volume_id&gt; 如何安装？详情见官方安装文档","link":"/2019/10/04/Docker基本命令入门/"},{"title":"java中的I/O演进之路","text":"I/O基础入门Java1.4 之前的早期版本，Java对I/O的支持并不完善，开人员在开发高性能I/O程序时是有非常大的困难的,总结有以下几点: 没有数据缓存区，I/O性能存在问题 没有C或者C++中的Channel概念，只有输入和输出流 同步阻塞I/O通行(BIO)，通常会导致通信线程被长时间阻塞。 文件的字符集有限，硬件移值性不好 因为以上的一些缺陷,所以在很长的一段时间内，服务器端的开发领域一直被C++和C长期占据。 Linux 网络I/O模型简介Linux的内核将所有的外部设备都看作一个文件来操作，对一个文件的读写操作会调用内核提供的系统命令，返回一个 file descriptor(fd, 文件描述符)。而对一个socket的读写也会有相应的描述符，称为 socketfd(socket 描述符)，描述符就是一个数字，它指向内核中的一个结构体(文件路径，数据区等属性)。 UNIX网络编程对I/O模型的分类，UNIX提供了5种I/O模型阻塞IO模型(BIO)：最常用的I/O模型就是阻塞模型，缺省的情形下，所有的文件操作都是阻塞的。我们以套接字接口为例来讲解此模型:在进程空间中调用recvfrom，其系统调用直到数据包到达且被复制到应用进程的缓冲区或者发生错误的时候才返回，否则，在此期间一直会等待，进程在从调用recvfrom开始到它返回的整段时间都是被阻塞的，因此被称为阻塞I/O模型。 如下图： 非阻塞(NIO)： refcvfrom从应用层到内核的时候，如果该缓冲区没有数据的话，就直接返回一个EWOULDBLOCK错误，一般来说非阻塞I/O模型进行轮寻检查这个状态，看内核是不是有数据到来。 I/O复用模型： Linux 提供select/poll，进程通过将一个或多个fd传递给select 或poll系统调用，阻塞在select操作上，这样select/poll可以帮助我们侦测多个fd是否处于就绪状态，select/poll是顺序扫描fd是否就绪，而且支持的fd数量有限，因此它的使用受到一些限制，Linux还提供了一个epoll系统调用，epoll使用基于事件驱动方式代替顺序扫描，因此性能更高，当有fd准备就绪时，就立即回调函数rollback。如下图所示: 信号驱动I/O模型：首先开启套接口信号驱动I/O功能，并通过系统调用sigaction执行一个信号处理函数(此系统调用立即返回，进程继续工作，它是非阻塞的)。当数据准备就绪时，就为该进程生成一个SIGIO信号，通过信号回调通知应用程序调用recvfrom来读取数据，并通知主循环函数处理数据，如下图： 异步I/O：告知内核启动某个操作，并让内核在整个操作完成后(包括将数据从内核复制到用户自己的缓冲区)通知我们。这种模型与信号量驱动模型的主要区别是: 信号驱动I/O由内核通知我们何时可以开始一个I/O操作，异步Java NIO的核心类库多路复用器selector 就是基于 epoll 的多路复用技术实现。I/O模型由内核通知我们I/O已经完成。如下图： I/O多路复用技术在I/O编程过程中，当需要同时处理多个客户端接入请求时，可以利用多个线程或者I/O多路复用技术进行处理，I/O多路复用技术通过把多个I/O的阻塞复用到同一个select的阻塞上，从而使得系统在单线程中可以同时处理多个客户端请求，与传统的多线程/多进程，模型比，I/O多路复用的最大优势是系统开销小，系统不需要创建新的额外进程或者线程，也不需要维护这些进程和线程的运行，降低了系统的维护工作量，节省了系统资源，I/O多路复用的主要应用场景如下： 服务器需要同时处理多个处于监听状态或者多个连接状态的套接字 服务器需要同时处理多种网络协议的套接字 目前支持I/O多路复用的系统调用有select、pselect、poll、epoll, 在Linux网络编程过程中，很长一段时间都使用select做轮询和网络事件通知，然而select的一些固有缺陷导致了它受到了很大的限制，最终Linux不得不在新的内核版本中寻找select的替代方案，最终选择了epoll与select的原理比较类似。 为了克服 select的缺点， epoll 做了很大的改进: 1.支持一个进程打开的socket描述符(FD)不受限制(仅受限于操作系统的最大文件句柄数。 select最大的缺陷就是单个进程锁打开的FD是有一定限制的，它由FD_SETSIZE设置，默认值是1024,对于那些需要支持上万个TCP连接的大型服务器来说显然太少了。可以选择修改这个宏然后重新编译内核，不过这会带来网络效率的下降。我们也可以通过选择多个进程的方案(传统的Apache 方案)解决这个问题，不过虽然在Linux上创建进程的代价比较小，但仍然是不可忽视的，另外，进程间的数据交换非常麻烦，对于java来说，由于没有共享内存，需要通过Socket通讯或者其他方式进行数据同步，这带来了额外的性能损耗，增加了程序的复杂度，所以这也不是一个完美的解决方案。 但是值得庆幸的是， epoll并没有这个限制，它所支持的FD上限是操作系统的最大文件句柄数，这个数字远远大于1024。例如: 在1GB内存的机器上大约10万个文件句柄左右，具体的值可以通过cat /proc/sys/fs/file -max 查看，通常情况下这个值跟系统的内存关系比较大。 2.I/O效率不会随着FD数目的增加而线性下降。 传统 select/poll的另一个致命的弱点，就是当你拥有一个很大的socket 集合时，由于网络的延时或者链路空闲，任一时刻只有少部分的socket是”活跃”的,但是 select/poll 每次调用都会线性扫描全部的集合，导致效率呈现线性下降。epoll 不存在这个问题，它只会对”活跃”的socket 进行操作——这是因为在内核实现中，epoll 是根据每个fd上面的callback函数实现的。那么，只有”活跃”的socket 才会去主动调用callback函数，其他idle状态的socket则不会。在这点上，epoll实现了一个伪AIO. 针对 epoll和select性能对比的benchmark 测试表明: 如果所有的socket都处于活跃状态——例如一个高速LAN环境，epoll并不比select/poll 效率高太多；相反，如果过多使用epoll_ctl， 效率相比还有稍微地降低。但是一旦使用 idle connections 模拟WAN环境，epoll的效率就远在select/poll 之上了。 3.使用mmap加速内核与用户空间的消息传递。 无论是select、poll还是epoll都需要内核把FD消息通知给用户空间，如何避免不必要的内存复制就显得非常重要，epoll是通过内核和用户空间mmap同一块内存来实现的。 4.epoll的API更加简单。 Java的I/O演进在JDK 1.4 推出Java NIO 之前，基于Java 的所有Socket 通信都采用同步阻塞模式(BIO)，这种一请求一问答的通信模型简化了上层的应用开发，但是在性能和可靠性方面却存在巨大的瓶颈。因此很长的一段时间里，大型的应用服务器都采用 C 或者 C++ 语言开发，因为他们可以直接使用操作系统中的异步I/O或者AIO能力，当并发访问量增大、响应时间延迟增大之后，采用Java BIO开发的服务端软件只有通过硬件的不断扩容来满足高并发和低延时，它极大的增加了企业的成本，并且随着集群规模的不断膨胀，系统的可维护性也面临巨大的挑战，只有通过采购性能更好的硬件服务器来解决问题，这导致恶性的循环。 正是 Java 传统的BIO的劣性，才使得Java 支持非阻塞I/O的呼声日渐个高涨，最终 JDK 1.4 中提供了新的NIO 类库，Java也可以支持非阻塞I/O了。 Java 的I/O 发展JDK1.4 新增 java.nio 包，提供了很多进行异步I/O开发的API和类库，主要的类和接口如下： 进行异步I/O操作的缓冲区ByteBuffer等; 进行异步I/O操作的管道Pipe; 进行各种I/O操作(异步或者同步)的Channel，包括ServerSocketChannel和SocketChannel; 多种字符集的编码能力和解码能力; 实现非阻塞I/O操作的多路复用器selector; 基于流行的Perl实现的正则表达式类库; 基于流行的Perl 实现的正则表达式类库; 文件通道FileChannel。 新的NIO类库的提供极大的促进基于Java 的异步非阻塞编程的发展和应用,但是，它依然有不完善的地方，特别是对文件系统的处理能力仍显得不足，主要的问题如下： 没有统一的文件属性(例如读写权限) API能力比较弱，例如目录的级联创建和递归遍历，往往需要自己实现 底层存储系统的一些高级API无法使用 所有的文件操作都是同步阻塞调用，不支持异步文件读写操作 2011 年 JDK1.7正式发布，它的一个比较大的亮点是将原来的NIO类库进行了升级，被称为 NIO2.0， 它主要有如下三个方面的改进： 提供能够批量获取文件属性的API，这些API具有平台无关性，不与特定的文件系统相耦合，另外它还提供了标准文件系统的SPI，供各个服务提供商扩展实现 提供AIO功能，支持基于文件的异步操作和针对网络套接字的异步操作","link":"/2019/10/03/java中的I-O演进之路/"},{"title":"Java并发(一)","text":"我们在找工作时，经常在招聘信息上看到有这么一条:有构建大型互联网服务及高并发等经验，你第一时间想到的是媒体常说的双十一吗？带着问题，我们一起思考技术…. 高并发 它是互联网分布式系统架构设计中必须考虑的因素之一，通常是指，保证系统能够同时并行化处理海量请求 同步和异步同步：发送一个请求，等待返回，然后再发送下一个请求。提交请求 -&gt; 等待服务器处理 -&gt; 处理完返回，此期间客户端浏览器不能干任何事异步：发送一个请求，不等待返回，随时可以再发送下一个请求。提交请求 -&gt; 服务器处理（这时浏览器仍然可以作其他事情）-&gt; 处理完毕 从上图可以知道，随着实时间的轨迹，同步一步一步的执行着，在异步中，当一个异步过程调用发出后，调用者不能立即得到结果，实际上会开启一个线程执行这部分内容，这个线程处理完了之后，通过状态，通知和回调来通知调用者来处理。 并发和并行 单核CPU(单处理器)上，只可能存在并发而不可能存在并行。 并行在多处理器系统中存在，而并发可以在单处理器和多处理器系统中都存在，并发能够在单处理器系统中存在是因为并发是并行的假象，并行要求程序能够同时执行多个操作，而并发只是要求程序假装同时执行多个操作（每个小时间片执行一个操作，多个操作快速切换执行） 临界区临界区用来表示一种公共资源或者说是共享数据，可以被多个线程使用，但是每一次，只能有一个线程使用它，一旦临界去资源被占用，其他线程想要使用这个资源，就必须等待。 这就是我们编程中经常要加锁的地方，如 synchronized 关键字，或是 Lock 接口。 阻塞和非阻塞 阻塞(Blocking)和非阻塞(Non-Blocking)通常用来形容多线程间的相互影响，比如一个线程占用临界区资源，那么其他所有需要这个资源的线程就必须在这个临界区中进行等待，等待会导致线程挂起，这种情况就是阻塞。如果占用资源的线程一直不愿意释放资源，那么其它所有阻塞在这个临界区上的线程都不能工作。 非阻塞允许多个线程同时进入临界区。 死锁、饥饿、活锁 死锁： 指两个或两个以上的进程（或线程）在执行过程中，因争夺资源而造成的一种互相等待的现象，若无外力作用，它们都将无法推进下去。此时称系统处于死锁状态或系统产生了死锁，这些永远在互相等待的进程称为死锁进程。 互斥条件：线程对资源的访问是排他性的，如果一个线程对占用了某资源，那么其他线程必须处于等待状态，直到资源被释放。 请求和保持条件：线程T1至少已经保持了一个资源R1占用,但又提出对另一个资源R2请求，而此时，资源R2被其他线程T2占用，于是该线程T1也必须等待，但又对自己保持的资源R1不释放。 不剥夺条件：线程已获得的资源，在未使用完之前，不能被其他线程剥夺，只能在使用完以后由自己释放。 环路等待条件：在死锁发生时，必然存在一个“进程-资源环形链”，即：{p0,p1,p2,…pn},进程p0（或线程）等待p1占用的资源，p1等待p2占用的资源，pn等待p0占用的资源。（最直观的理解是，p0等待p1占用的资源，而p1而在等待p0占用的资源，于是两个进程就相互等待 活锁： 指线程T1可以使用资源，但它很礼貌，让其他线程先使用资源，线程T2也可以使用资源，但它很绅士，也让其他线程先使用资源。这样你让我，我让你，最后两个线程都无法使用资源。 在街上遇到一妹子，刚好她朝着你的反方向走，与你正面碰到，你们都想让彼此过去。你往左边移，她也往左边移，两人还是无法过去。这时你往右边移，她也往右边移，如此循环下去。 饥饿： 指如果线程T1占用了资源R，线程T2又请求封锁R，于是T2等待。T3也请求资源R，当T1释放了R上的封锁后，系统首先批准了T3的请求，T2仍然等待。然后T4又请求封锁R，当T3释放了R上的封锁之后，系统又批准了T4的请求……，T2可能永远等待。 有两条道A和B上都堵满了车辆，其中A道堵的时间最长，B相对相对堵的时间较短，这时，前面道路已疏通，交警按照最佳分配原则，示意B道上车辆先过，B道路上过了一辆又一辆，A道上排队时间最长的确没法通过，只能等B道上没有车辆通过的时候再等交警发指令让A道依次通过，这也就是 ReentrantLock 显示锁里提供的不公平锁机制（当然了，ReentrantLock 也提供了公平锁的机制，由用户根据具体的使用场景而决定到底使用哪种锁策略），不公平锁能够提高吞吐量但不可避免的会造成某些线程的饥饿。 并发级别分为 阻塞 和 非阻塞（非阻塞分为无障碍、无锁、无等待） 阻塞 当一个线程进入临界区后，其他线程必须等待 无障碍 无障碍是一种最弱的非阻塞调度 可自由出入临界区 无竞争时，有限步内完成操作 有竞争时，回滚数据 和非阻塞调度相比呢，阻塞调度是一种悲观的策略，它会认为说一起修改数据是很有可能把数据改坏的。而非阻塞调度呢，是一种乐观的策略，它认为大家修改数据未必把数据改坏。 但是它是一种 宽进严出 的策略，当它发现一个进程在临界区内发生了数据竞争，产生了冲突，那么无障碍的调度方式则会回滚这条数据。 在这个无障碍的调度方式当中，所有的线程都相当于在拿去一个系统当前的一个快照。他们一直会尝试拿去的快照是有效的为止。 无锁 是无障碍的 保证有一个线程可以胜出 与无障碍相比，无障碍并不保证有竞争时一定能完成操作，因为如果它发现每次操作都会产生冲突，那它则会不停地尝试。如果临界区内的线程互相干扰，则会导致所有的线程会卡死在临界区，那么系统性能则会有很大的影响。 而无锁增加了一个新的条件，保证每次竞争有一个线程可以胜出，则解决了无障碍的问题。至少保证了所有线程都顺利执行下去。 下面代码是Java中典型的无锁计算代码: 123while (!atomicVar.compareAndSet(localVar, localVar+1)) { localVar = atomicVar.get(); } 无等待 无锁的 要求所有的线程都必须在有限步内完成 无饥饿的 无等待的前提是无锁的基础上的，无锁它只保证了临界区肯定有进也有出，但是如果进的优先级都很高，那么临界区内的某些优先级低的线程可能发生饥饿，一直出不了临界区。那么无等待解决了这个问题，它保证所有的线程都必须在有限步内完成，自然是无饥饿的。 无等待是并行的最高级别，它能使这个系统达到最优状态。无等待的典型案例：只有读线程，没有写线程，那么这个则必然是无等待的。 如果既有读线程又有写线程，而每个写线程之前，都把数据拷贝一份副本，然后修改这个副本，而不是修改原始数据，因为修改副本，则没有冲突，那么这个修改的过程也是无等待的。最后需要做同步的只是将写完的数据覆盖原始数据。由于无等待要求比较高，实现起来比较困难，所以无锁使用得会更加广泛一些。 关于并行的2个重要定律两个定律都与加速比有关 阿姆达尔定律 Amdahl定律(阿姆达尔定律)：定义了串行系统并行化后的加速比的计算公式和理论上限（加速比=优化前系统耗时/优化后系统耗时） 一个程序（或者一个算法）可以按照 是否可以被并行化 分为下面两个部分： 可以被并行化的部分 不可以被并行化的部分 假设一个程序处理磁盘上的文件。这个程序的一小部分用来扫描路径和在内存中创建文件目录。做完这些后，每个文件交个一个单独的线程去处理。扫描路径和创建文件目录的部分不可以被并行化，不过处理文件的过程可以。 阿姆达尔定律 增加CPU处理器的数量并不一定能起到有效的作用，提高系统内可并行化的模块比重，合理增加并行处理器数量，才能以最小的投入，得到最大的加速比。 古斯塔夫森定律 Gustafson定律(古斯塔夫森)：说明处理器个数，串行比例和加速比之间的关系。 只要有足够的并行化，那么加速比和CPU个数成正比。","link":"/2019/10/02/Java并发-一/"},{"title":"单例模式之静态内部类实现","text":"单例模式是一种常用的软件设计模式。在它的核心结构中只包含一个被称为单例的特殊类。通过单例模式可以保证系统中，应用该模式的一个类只有一个实例。即一个类只有一个对象实例。 最常用的单例模式有恶汉式和懒汉式两种方式，除此之外还有一种通过静态内部类实现的单例模式。 代码示例1234567891011121314151617181920212223public class Singleton{ private Singleton(){} static { System.out.println(\"This's static code block!\"); } private static class SingletonHandler { private static Singleton singleton = new Singleton(); static { System.out.println(\"This's innerClass's static code block\"); } } public static Singleton getInstance(){ return SingletonHandler.singleton; } public static void display(){ System.out.println(\"This's display!\"); }} 1234567891011121314151617181920212223242526272829public class SingletonTest{ private SingletonTest(){} static class MyThread extends Thread { @Override public void run() { super.run(); System.out.println(\"Thread running_\"+Singleton.getInstance()); } } public static void main(String[] args) { MyThread th1 = new MyThread(); MyThread th2 = new MyThread(); MyThread th3 = new MyThread(); /*@1 th1.start(); th2.start(); th3.start(); */ /*@2 Singleton.display(); */ }} 运行结果及解释情况一(注释 @1代码，注释 @2的代码) //运行结果 为空 解释：外部类和内部类都没有加载。 情况二(执行 @1代码) //运行结果This’s static code block!This’s innerClass’s static code blockThread running_com.singleton.Singleton@4f19c297Thread running_com.singleton.Singleton@4f19c297Thread running_com.singleton.Singleton@4f19c297解释： 外部类Singleton和内部类SingletonHandler都加载了，因为他们的静态代码块加载了。 情况三(注释 @1代码，执行 @2的代码) //运行结果This’s static code block!This’s display!解释：外部类加载了，而内部类没有加载，因为加载了类，就一定会执行静态代码块。 结论终上实验：内部类SingletonHandler只有在getInstance()方法第一次调用的时候才会被加载（实现了延迟加载效果），而且其加载过程是线程安全的（实现线程安全）。内部类加载的时候只实例化了一次instance。","link":"/2018/10/15/单例模式之静态内部类实现/"},{"title":"学习使用git","text":"GIT （分布式版本控制系统）Git(读音为/gɪt/)是一个开源的分布式版本控制系统，可以有效、高速地处理从很小到非常大的项目版本管理。Git 是 Linus Torvalds 为了帮助管理 Linux 内核开发而开发的一个开放源码的版本控制软件。 创建markdown文件 1touch README.md 创建.gitignore文件 1touch .gitignore 初始化仓库 1git init 查看变化 1git status 添加所有的变更文件 1git add . 只是提交到本地仓库中 1git commit -am 'first commit init project' 添加到远程仓库中 1git remote add origin ’git地址’ 查看当前分支 1git branch 本地仓库推送到远程仓库 123456git push -u origin master1.如果是第一次整合项目到git上会提示失败，需要先git pull把现在远程分支上的文件拉到本地上来，2.git push -u origin master，3.如果再报错就强制推上去，git push -u -f origin master; 查看远程分支 1git branch -r 在远程master上开一个v1.0分支 1git checkout -b v1.0 origin/master 查看是否切换到新建的分支 1git branch 推送分支到远程 1git push origin HEAD -u","link":"/2018/08/30/学习使用git/"}],"tags":[{"name":"docker","slug":"docker","link":"/tags/docker/"},{"name":"java并发","slug":"java并发","link":"/tags/java并发/"},{"name":"java基础","slug":"java基础","link":"/tags/java基础/"},{"name":"netty","slug":"netty","link":"/tags/netty/"},{"name":"设计模式","slug":"设计模式","link":"/tags/设计模式/"},{"name":"git的使用","slug":"git的使用","link":"/tags/git的使用/"}],"categories":[{"name":"docker","slug":"docker","link":"/categories/docker/"},{"name":"java","slug":"java","link":"/categories/java/"},{"name":"tomcat","slug":"tomcat","link":"/categories/tomcat/"},{"name":"netty","slug":"netty","link":"/categories/netty/"},{"name":"设计模式","slug":"设计模式","link":"/categories/设计模式/"},{"name":"git","slug":"git","link":"/categories/git/"}]}